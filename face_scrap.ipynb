{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Detect and Extract Faces from an Image with OpenCV and Python\n",
    "\n",
    "source: https://www.digitalocean.com/community/tutorials/how-to-detect-and-extract-faces-from-an-image-with-opencv-and-python\n",
    "\n",
    "## Step 1 - Configuring the Local Environment\n",
    "\n",
    "Before you begin writing your code, you will first create a workspace to hold the code and install a few dependencies.\n",
    "\n",
    "Create a directory for the project with the mkdir command:\n",
    "\n",
    "``` \n",
    "mkdir face_scrapper \n",
    "```\n",
    "Change into the newly created directory:\n",
    "```\n",
    "cd face_scrapper\n",
    "```\n",
    "Next, you will create a virtual environment for this project. Virtual environments isolate different projects so that differing dependencies won’t cause any disruptions. Create a virtual environment named face_scrapper to use with this project:\n",
    "```\n",
    "python -m virtualenv face_scrapper\n",
    "```\n",
    "Activate the isolated environment:\n",
    "```\n",
    "source face_scrapper/bin/activate\n",
    "```\n",
    "\n",
    "Now that you’ve activated your virtual environment, you will use nano or your favorite text editor to create a requirements.txt file. This file indicates the necessary Python dependencies:\n",
    "```\n",
    "nano requirements.txt\n",
    "```\n",
    "Next, you need to install three dependencies to complete this tutorial:\n",
    "\n",
    "- numpy: numpy is a Python library that adds support for large, multi-dimensional arrays. It also includes a large collection of mathematical functions to operate on the arrays.\n",
    "- opencv-utils: This is the extended library for OpenCV that includes helper functions.\n",
    "- opencv-python: This is the core OpenCV module that Python uses.\n",
    "\n",
    "Add the following dependencies to the file requirements.txt:\n",
    "\n",
    "**numpy**\n",
    "\n",
    "**opencv-utils**\n",
    "\n",
    "**opencv-python**\n",
    "\n",
    "Save and close the file: ^X, Yes.\n",
    "\n",
    "Install the dependencies by passing the requirements.txt file to the Python package manager, pip. The -r flag specifies the location of requirements.txt file.\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "In this step, you set up a virtual environment for your project and installed the necessary dependencies. You’re now ready to start writing the code to detect faces from an input image in next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy\n",
    "pip install opencv-utils\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Writing and Running the Face Detector Script\n",
    "In this section, you will write code that will take an image as input and return two things:\n",
    "\n",
    "The number of faces found in the input image.\n",
    "A new image with a rectangular plot around each detected face.\n",
    "Start by creating a new file to hold your code:\n",
    "```\n",
    "nano app.py\n",
    "```\n",
    "In this new file, start writing your code by first importing the necessary libraries. You will import two modules here: cv2 and sys. The cv2 module imports the OpenCV library into the program, and sys imports common Python functions, such as argv, that your code will use.\n",
    "```\n",
    "import cv2\n",
    "import sys\n",
    "```\n",
    "Next, you will specify that the input image will be passed as an argument to the script at runtime. The Pythonic way of reading the first argument is to assign the value returned by sys.argv[1] function to an variable:\n",
    "```\n",
    "...\n",
    "imagePath = sys.argv[1]\n",
    "```\n",
    "A common practice in image processing is to first convert the input image to gray scale. This is because detecting luminance, as opposed to color, will generally yield better results in object detection. Add the following code to take an input image as an argument and convert it to grayscale:\n",
    "```\n",
    "...\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "The .imread() function takes the input image, which is passed as an argument to the script, and converts it to an OpenCV object. Next, OpenCV’s .cvtColor() function converts the input image object to a grayscale object.\n",
    "\n",
    "Now that you’ve added the code to load an image, you will add the code that detects faces in the specified image:\n",
    "```\n",
    "...\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    ")\n",
    "\n",
    "print(\"Found {0} Faces!\".format(len(faces)))\n",
    "```\n",
    "This code will create a faceCascade object that will load the Haar Cascade file with the cv2.CascadeClassifier method. This allows Python and your code to use the Haar Cascade.\n",
    "\n",
    "Next, the code applies OpenCV’s .detectMultiScale() method on the faceCascade object. This generates a list of rectangles for all of the detected faces in the image. The list of rectangles is a collection of pixel locations from the image, in the form of Rect(x,y,w,h).\n",
    "\n",
    "Here is a summary of the other parameters your code uses:\n",
    "\n",
    "- *gray*: This specifies the use of the OpenCV grayscale image object that you loaded earlier.\n",
    "- *scaleFactor*: This parameter specifies the rate to reduce the image size at each image scale. Your model has a fixed scale during training, so input images can be scaled down for improved detection. This process stops after reaching a threshold limit, defined by maxSize and minSize.\n",
    "- *minNeighbors*: This parameter specifies how many neighbors, or detections, each candidate rectangle should have to retain it. A higher value may result in less false positives, but a value too high can eliminate true positives.\n",
    "- *minSize*: This allows you to define the minimum possible object size measured in pixels. Objects smaller than this parameter are ignored.\n",
    "\n",
    "After generating a list of rectangles, the faces are then counted with the len function. The number of detected faces are then returned as output after running the script.\n",
    "\n",
    "Next, you will use OpenCV’s .rectangle() method to draw a rectangle around the detected faces:\n",
    "```\n",
    "...\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "```\n",
    "This code uses a for loop to iterate through the list of pixel locations returned from faceCascade.detectMultiScale method for each detected object. The rectangle method will take four arguments:\n",
    "\n",
    "- *image* tells the code to draw rectangles on the original input image.\n",
    "- *(x,y), (x+w, y+h)* are the four pixel locations for the detected object. rectangle will use these to locate and draw rectangles around the detected objects in the input image.\n",
    "- *(0, 255, 0)* is the color of the shape. This argument gets passed as a tuple for BGR. For example, you would use (255, 0, 0) for blue. We are using green in this case.\n",
    "- *2* is the thickness of the line measured in pixels.\n",
    "\n",
    "Now that you’ve added the code to draw the rectangles, use OpenCV’s .imwrite() method to write the new image to your local filesystem as faces_detected.jpg. This method will return true if the write was successful and false if it wasn’t able to write the new image.\n",
    "```\n",
    "...\n",
    "status = cv2.imwrite('faces_detected.jpg', image)\n",
    "```\n",
    "Finally, add this code to print the return the true or false status of the .imwrite() function to the console. This will let you know if the write was successful after running the script.\n",
    "```\n",
    "...\n",
    "print (\"Image faces_detected.jpg written to filesystem: \",status)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Extracting Faces and Saving them Locally (Optional)\n",
    "\n",
    "add the highlighted lines under the cv2.rectangle line:\n",
    "```\n",
    "...\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    print(\"[INFO] Object found. Saving locally.\")\n",
    "    cv2.imwrite(str(w) + str(h) + '_faces.jpg', roi_color)\n",
    "...\n",
    "```\n",
    "- The roi_color object plots the pixel locations from the faces list on the original input image. \n",
    "- The x, y, h, and w variables are the pixel locations for each of the objects detected from faceCascade.detectMultiScale method. \n",
    "The code then prints output stating that an object was found and will be saved locally.\n",
    "\n",
    "Once that is done, the code saves the plot as a new image using the cv2.imwrite method. It appends the width and height of the plot to the name of the image being written to. This will keep the name unique in case there are multiple faces detected.\n",
    "\n",
    "The full code look like this:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "imagePath = sys.argv[1]\n",
    "\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.3,\n",
    "    minNeighbors=3,\n",
    "    minSize=(30, 30)\n",
    ")\n",
    "\n",
    "print(\"[INFO] Found {0} Faces.\".format(len(faces)))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    print(\"[INFO] Object found. Saving locally.\")\n",
    "    cv2.imwrite(str(w) + str(h) + '_faces.jpg', roi_color)\n",
    "\n",
    "status = cv2.imwrite('faces_detected.jpg', image)\n",
    "print(\"[INFO] Image faces_detected.jpg written to filesystem: \", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Running the Script\n",
    "\n",
    "In this step, you will use an image to test your script. \n",
    "\n",
    "When you find an image you’d like to use to test, save it in the same directory as your app.py script.\n",
    "Once you have an image to test the script, run the script and provide the image path as an argument:\n",
    "```\n",
    "python app.py path/to/input_image\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python app.py picts/IMG_9772.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    " \n",
    "#get paths of each file in folder named Images\n",
    "#Images here contains my data(folders of various persons)\n",
    "imagePaths = list(paths.list_images('Images'))\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the person name from the image path\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    # load the input image and convert it from BGR (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #Use Face_recognition to locate faces\n",
    "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    # loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "#save emcodings along with their names in dictionary data\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "#use pickle to save data into a file for later use\n",
    "f = open(\"face_enc\", \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()\n",
    "```\n",
    "https://www.mygreatlearning.com/blog/face-recognition/\n",
    "https://www.mygreatlearning.com/blog/yolo-object-detection-using-opencv/?highlight=object\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
